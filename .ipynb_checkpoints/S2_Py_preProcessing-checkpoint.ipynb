{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"http://i.imgur.com/sSaOozN.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course: Computational Thinking for Governance Analytics\n",
    "\n",
    "### Prof. José Manuel Magallanes, PhD \n",
    "* Visiting Professor of Computational Policy at Evans School of Public Policy and Governance, and eScience Institute Senior Data Science Fellow, University of Washington.\n",
    "* Professor of Government and Political Methodology, Pontificia Universidad Católica del Perú. \n",
    "\n",
    "_____\n",
    "\n",
    "# Session 2:  Data Preprocessing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='beginning'></a>\n",
    "\n",
    "Preprocessing includes three stages:\n",
    "\n",
    "1. [Collecting](#part1) \n",
    "2. [Cleaning](#part2) \n",
    "3. [Formatting](#part3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "<a id='part1'></a>\n",
    "\n",
    "## Collecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collection is not a pre processing problem if you have data already nicely organized. When it is so, **pandas** will read the file without problem:\n",
    "\n",
    "* Reading STATA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stataFile='https://github.com/EvansDataScience/data/raw/master/lapopUSA2017_13.dta'\n",
    "##\n",
    "dataStata=pd.read_stata(stataFile,convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reading EXCEL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile='https://github.com/EvansDataScience/data/raw/master/hdi2016.xlsx'\n",
    "dataExcel=pd.read_excel(excelFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you just have seen, a common file type can be easily read using pandas. Once you have them, you can ask many things, some could be:\n",
    "\n",
    "* Number of rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataStata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* See the first rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataExcel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The property __shape__ is an attribute of the data frame, so you do not need parentheses; you do not these ones to call a function, in this last case __head()__. You also have __tail()__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataStata[['q12','q12m','q12f']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tail is showing only the last elements of the selected columns.\n",
    "\n",
    "* Self-collecting\n",
    "\n",
    "Another way to collect data is to create an online form and then get the data into Python. For this situation, go to this [link](https://goo.gl/forms/HX3KkxcEtXgMzyDJ3) and answer the questions.\n",
    "\n",
    "Then, I will see the answers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link='write here'\n",
    "#namesOfCols=['timeStamp','name','sex','age','bornIn','workingStatus']\n",
    "\n",
    "#myData = pd.read_csv(link,header=0,names=namesOfCols)\n",
    "\n",
    "# here it is:\n",
    "#myData.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information collected was retrieved in a comma-separated values format. This is a very common format. Notice the settings of __read_csv__: I tell pandas that the first row has the names of the columns (header is in position 0); and then I rename the headers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Collecting data from APIs\n",
    "\n",
    "Most of these data come in more complex formats, like XML or JSON format. Let's get the data about \n",
    "[Seattle Real Time Fire 911 Calls](https://dev.socrata.com/foundry/data.seattle.gov/grwu-wqtk). Let me follow the instructions from that website to get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sodapy\n",
    "\n",
    "from sodapy import Socrata\n",
    "\n",
    "client = Socrata(\"data.seattle.gov\", None)\n",
    "results = client.get(\"grwu-wqtk\", limit=1000)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "results_df = pd.DataFrame.from_records(results)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to page beginning](#beginning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "<a id='part2'></a>\n",
    "\n",
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files opened above look clean because they may have been produce professionally for statistical work, or because the collecting tool was very restrictive. However, several data that you collect may not bring you the data as clean as the ones found in the previous codes. This commmon webpage has a table that may be needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiLink=\"https://en.wikipedia.org/wiki/List_of_freedom_indices\"\n",
    "\n",
    "\n",
    "import IPython\n",
    "iframe = '<iframe src=' + wikiLink + ' width=700 height=350></iframe>'\n",
    "IPython.display.HTML(iframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to get the table using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wikiTables=pd.read_html(wikiLink,header=0,attrs={'class': 'wikitable sortable'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to get all the tables. I may have more than one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do I have? / How many?\n",
    "type(wikiTables), len(wikiTables) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to recover the first table from the list (the only one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=wikiTables[0]\n",
    "\n",
    "#what is it?\n",
    "type(DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!...we have a data frame; then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data frame does not look like the one we see on the website. We need to improve the call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install 'beautifulsoup4'\n",
    "DF=pd.read_html(wikiLink,header=0,flavor='bs4',attrs={'class': 'wikitable sortable'})[0]\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining BeautifulSoup (BS) and Pandas gave us the right result. But our work is not over.\n",
    "\n",
    "Pay attention to the cleaning pandas+BS have done: the 'n/a' was interpreted as **NaN**; no country flags in the data; and the headers are in the right place. \n",
    "\n",
    "However, to prepare a final data set, we should pay attention to the headers names to avoid _blanks_, and erase the _footnote_ call.\n",
    "\n",
    "We can have two strategies:\n",
    "* Brute-force!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we had a small number of names to change, we can use brute-force strategy:\n",
    "DF.columns=['Country',\n",
    " 'FreedomintheWorld',\n",
    " 'IndexofEconomicFreedom',\n",
    " 'PressFreedomIndex',\n",
    " 'DemocracyIndex']\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using more computational thinking (algorithmic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we had many columns, writing an algorith to rename the columns could be better:\n",
    "\n",
    "# recalling the data:\n",
    "DF=pd.read_html(wikiLink,header=0,flavor='bs4',attrs={'class': 'wikitable sortable'})[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just recalled the data to do several steps:\n",
    "\n",
    "1. Find blanks.\n",
    "2. Find numbers.\n",
    "3. Find brackets (opening and closing).\n",
    "\n",
    "The previous requires a **regular expresssion**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # may need to be installed:\n",
    "\n",
    "# find blanks: \\\\s+\n",
    "# find numbers: \\\\d+\n",
    "# find opening bracket : \\\\[\n",
    "# find closing bracket: \\\\]\n",
    "\n",
    "# You can combine using '|' (or):\n",
    "pattern='\\\\s+|\\\\d+|\\\\[|\\\\]'\n",
    "nothing=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how this works for one case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testString='Freedom in the World 2018[10]'\n",
    "re.sub(pattern,nothing,testString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how this works for ALL cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[re.sub(pattern,nothing,name) for name in DF.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify we are matching well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNames=[re.sub(pattern,nothing,name) for name in DF.columns]\n",
    "\n",
    "# checking:\n",
    "list(zip(DF.columns,newNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn that match into a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{old:new for old,new in zip(DF.columns,newNames)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a dict like that one, you can use it to rename the columns with another function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes={old:new for old,new in zip(DF.columns,newNames)}\n",
    "DF.rename(columns=changes,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you had a set of new names, and you do not want to change every column name, that is the correct way to do it.\n",
    "\n",
    "Let's see the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A next step will be verifying if the answers are well coded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.iloc[:,1::].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What were you looking for? \n",
    "Sometimes a category may be wrongly written in a cell, for instance, if you had 'Free' and 'free' or 'free ' to represent the same in one column, you have a mistake. Let's see if there is one here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.FreedomintheWorld.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " What we see is that this variable has its own correct set of answers. \n",
    " \n",
    " We can try that approach for each variable, but we can check the whole group of categorical values like thisL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF.iloc[:,1::] all columns but the first one\n",
    "# apply(set)  apply the function 'set()'  per column\n",
    "# tolist() convert to a list \n",
    "\n",
    "DF.iloc[:,1::].apply(set).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to page beginning](#beginning)\n",
    "____\n",
    "<a id='part3'></a>\n",
    "## Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data seems _clean_, but we need now to be sure the information is in the right format. This varies according to the project; so, let me show you some steps during of the formatting stage.\n",
    "\n",
    "1. Verify the data types:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All but the first variable are categories, not text (_object_). To convert them into categories you can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headerNames=DF.columns\n",
    "DF[headerNames[1:]]=DF[headerNames[1:]].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a variable is of categorical type, you can use particular functions for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.FreedomintheWorld.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.IndexofEconomicFreedom.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.PressFreedomIndex.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.DemocracyIndex.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. If ordinal, make the adjustment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order in which the categories differentiate a plain categorical from an ordinal categorical. They should be categorical but the order does not reflect the order it should. \n",
    "\n",
    "We can turn it into an ordinal doing the following:\n",
    "\n",
    "a. Find a good numeric sequence for the ordinal values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice I am using the numbers in the same order as the list of categorical values:\n",
    "oldFree=list(DF.FreedomintheWorld.cat.categories)\n",
    "\n",
    "# '5 very good' / '4 good' / '3 middle' / '2 bad' / '1 very bad'\n",
    "\n",
    "newFree=[5,1,3]\n",
    "recodeFree={old:new for old,new in zip (oldFree,newFree)}\n",
    "\n",
    "oldEco=list(DF.IndexofEconomicFreedom.cat.categories)\n",
    "newEco=[5,3,4,2,1]\n",
    "recodeEco={old:new for old,new in zip (oldEco,newEco)}\n",
    "\n",
    "oldPress=list(DF.PressFreedomIndex.cat.categories)\n",
    "newPress=[2,5,3,4,1]\n",
    "recodePress={old:new for old,new in zip (oldPress,newPress)}\n",
    "\n",
    "oldDemo=list(DF.DemocracyIndex.cat.categories)\n",
    "newDemo=[1,4,5,2]\n",
    "recodeDemo={old:new for old,new in zip (oldDemo,newDemo)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Rename the still plain categorical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.FreedomintheWorld.cat.rename_categories(recodeFree,inplace=True)\n",
    "\n",
    "DF.IndexofEconomicFreedom.cat.rename_categories(recodeEco,inplace=True)\n",
    "\n",
    "DF.PressFreedomIndex.cat.rename_categories(recodePress,inplace=True)\n",
    "\n",
    "DF.DemocracyIndex.cat.rename_categories(recodeDemo,inplace=True)\n",
    "\n",
    "# veamos:\n",
    "DF.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Now turn the renamed columns into a numeric values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[headerNames[1:]]=DF[headerNames[1:]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Try solving missing data presence\n",
    "\n",
    "The data has some missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the thinking: How to replace the missing values?\n",
    "\n",
    "Python can easily find and replace every missing value; but our strategy will be different:\n",
    "\n",
    "* _Freedom in the World_ has the least missing values, we will use this variable to see how the others behave.\n",
    "\n",
    "* Since the variables are ordinals (even though they are numbers now) a good candidate to impute a missing is the median NOT the mean (you can not compute the mean of an ordinal).\n",
    "\n",
    "Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median per group: \n",
    "DF.groupby('FreedomintheWorld')[headerNames[2:]].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to replace those medians whenever a missing value is found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in headerNames[2:]:\n",
    "    # in each column, get median by FIW group, and use it to replace the missing values.\n",
    "    DF[col].fillna(DF.groupby([\"FreedomintheWorld\"])[col].transform(\"median\"), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can send this to R, in a simple CSV format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DF.to_csv(\"indexes.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "## More examples\n",
    "\n",
    "### Case: Democracy Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me clean a similar data from wikipedia, about democracy index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #location:\n",
    "demoLink = \"https://en.wikipedia.org/wiki/Democracy_Index\" \n",
    "\n",
    "#collection\n",
    "demodex=pd.read_html(demoLink,header=0,flavor='bs4',attrs={'class': 'wikitable sortable'})[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Looking for messiness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's on top?\n",
    "# names? weird symbols? more links?\n",
    "demodex.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's at the bottom?\n",
    "# note? credits? extra info?\n",
    "\n",
    "demodex.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we see a column that have some messiness (symbol \"=\" in rank), but which can be deleted as their information is not relevant. Let me get rid of the _Score_, as it is just the mean of the other ones. The last row is the repetition of the headers, so that one should go, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bye row 167, and two columns\n",
    "demodexClean=demodex.drop(index=167,columns=['Rank','Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodexClean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are few names, we can change to smaller sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNames=['plularism','effectiveness','participation','culture','liberties']\n",
    "\n",
    "# names from the second and before the last one '[1:-1]':\n",
    "newMapper={old:new for old,new in zip(demodexClean.columns[1:-1],newNames)}\n",
    "\n",
    "demodexClean.rename(columns=newMapper,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is what we have so far:\n",
    "demodexClean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks good so far. Let's go to formatting.\n",
    "\n",
    "2. Giving the rigth format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking data types:\n",
    "demodexClean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we realized the need to make some indices into numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodexClean[newNames]=demodexClean[newNames].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last one is a categorical variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodexClean.Category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have text, you could get the unique values of a column like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(demodexClean.Category).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can prepare the map to recode the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldValues=pd.unique(demodexClean.Category).tolist()\n",
    "newValues=[4,3,2,1]\n",
    "mapNewOld={old:new for old,new in zip(oldValues,newValues)}\n",
    "mapNewOld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do it in this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodexClean.Category.replace(mapNewOld,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or this one:\n",
    "# demodexClean.Category=demodexClean.Category.replace(mapNewOld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save it as a category, but that will be lost if sent to R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodexClean.Category=demodexClean.Category.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodexClean['Category'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking missing values\n",
    "\n",
    "demodexClean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is now ready for R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demodexClean.to_csv(\"democracyIndex.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The case of Medicare:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will use data from [Medicare Beneficiary Enrollment and Demographics](https://dev.socrata.com/foundry/data.wa.gov/2cup-2fnu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# This time I am talking to the API from DATA.WA.GOV\n",
    "url = \"https://data.wa.gov/resource/2cup-2fnu.json?year=2014\"\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    medicare = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning json into DF:\n",
    "medicare2014 = pd.DataFrame(medicare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicare2014.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicare2014.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first row is the total, it has to go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this one?\n",
    "medicare2014.drop(index=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or this one?\n",
    "medicare2014.drop(index=0).reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or this one?\n",
    "medicare2014.drop(index=0).reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use inplace, we should not concatenate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicare2014.drop(index=0,inplace=True)\n",
    "medicare2014.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicare2014.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what we have\n",
    "medicare2014.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the three variables before the last one, and county should be kept as objects, while the other should be numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get original order:\n",
    "original=medicare2014.columns.tolist()\n",
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new order:  (no need for * if one element)\n",
    "newOrder=[original[3],*original[14:], *original[0:3],*original[4:14],] # using '*'\n",
    "newOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are differenet data types, let me move columns:\n",
    "\n",
    "medicare2014=medicare2014[newOrder]\n",
    "medicare2014.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can give the right format now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headerNames=medicare2014.columns\n",
    "medicare2014[headerNames[4::]]=medicare2014[headerNames[4::]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check data types:\n",
    "medicare2014.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicare2014.describe(include='all') # to include categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicare2014.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some missing values, but we will leave it so. So the last step will be just to save the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medicare2014.to_csv(\"medicare2014.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case: Public education:\n",
    "\n",
    "When you visit the [website](https://nces.ed.gov/ccd/) of the Common Core of Data from the US Department of Education, you can get a data set with detailed information on public schools at the state of Washington:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile='https://github.com/EvansDataScience/data/raw/master/wapubs.xlsx'\n",
    "schoolPub=pd.read_excel(dataFile) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Looking for messiness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoolPub.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first row is not the beginning of the table. We need to skip 11 rows; but pay attention to what you are deleting, as if is telling you how missing values were coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoolPub=pd.read_excel(dataFile,skiprows=11,na_values=['†','‡','–'])\n",
    "schoolPub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the tail:\n",
    "schoolPub.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The headers have blanks and symbols, getting rid of them here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import re  \n",
    "\n",
    "pattern='\\\\*|\\\\s+'\n",
    "nothing=''\n",
    "schoolPub.columns=[re.sub(pattern,nothing,columnName) for columnName in schoolPub.columns]\n",
    "schoolPub.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean names allow better exploring. Notice we solved the missing values above. You could have done this instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#symbolsForNA=['†','‡','–'] \n",
    "\n",
    "#import numpy as np  #numpy manages the nan for pandas\n",
    "#schoolPub.replace(symbolsForNA,np.nan,inplace=True) # in the whole data frame!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoolPub.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we cleaned the missing values, there might be more in the text columns that may be hidden. Obviously, 'SchoolName','District','CountyName','StreetAddress','City','State' are text, but the other are possibly categorical.\n",
    "\n",
    "So let me explore all the other ones, which are of type _object_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notUsed=['SchoolName','District','CountyName','StreetAddress','City','State']\n",
    " \n",
    "# These are the ones without the obvious text columns\n",
    "schoolPub.drop(notUsed,axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # These are the ones without the obvious text columns, but of the type 'object':\n",
    "schoolPub.drop(notUsed,axis=1).select_dtypes(include='object').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to see the categories there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoolPub.drop(notUsed,axis=1).select_dtypes(include='object').apply(set).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to take care of the missing value '**N**':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoolPub.Locale.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  #numpy manages the nan for pandas\n",
    "\n",
    "schoolPub.replace(['N'],np.nan,inplace=True) # in the whole data frame!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So:\n",
    "schoolPub.Locale.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important step could be to give add some text to make the school grades a recognizable ordering (considering the file will be read in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is wrong:\n",
    "'PK'<'KG'<'01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is OK:\n",
    "'-1 PK'<'0 KG'<'01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using replace:\n",
    "\n",
    "schoolPub.replace({'PK':\"-1 PK\", \"KG\":\"0 KG\"},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless you want to recode other [variables](https://nces.ed.gov/programs/edge/docs/LOCALE_CLASSIFICATIONS.pdf), we could save this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schoolPub.to_csv(\"schoolPub.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case: SNAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataFile=\"https://github.com/EvansDataScience/data/raw/master/cntysnap.xls\"\n",
    "snapBen=pd.read_excel(dataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first rows:\n",
    "snapBen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to skip some rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipping:\n",
    "\n",
    "snapBen=pd.read_excel(dataFile,skiprows=2)\n",
    "snapBen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the tail\n",
    "snapBen.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking names:\n",
    "snapBen.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of blanks:\n",
    "\n",
    "pattern='\\\\s+'\n",
    "nothing=''\n",
    "snapBen.columns=[re.sub(pattern,nothing,columnName) for columnName in snapBen.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a zero FIPS code, take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapBen[snapBen['CountyFIPScode']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are rows about States. I will keep the counties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapBenUSCounties=snapBen[snapBen['CountyFIPScode']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking data types:\n",
    "snapBenUSCounties.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counties tell you to what State they belong, so we could use that to create a new column. Let's see a simple example on how to get information from a text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using split,a function for strings:\n",
    "'Autauga County, AL'.split(', ') # notice the space after the comma\n",
    "# you get a list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **split**, in this case, returns the state in the second position of the list (index=1), then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving every second element for each element in the column:\n",
    "states=[element.split(', ')[1] for element in snapBenUSCounties.Name]\n",
    "\n",
    "# make that list a new column\n",
    "snapBenUSCounties=snapBenUSCounties.assign(StateName=states)\n",
    "\n",
    "# checking:\n",
    "snapBenUSCounties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new column was created. We could get rid of the state information from the counties column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just keep county names\n",
    "counties=[element.split(', ')[0] for element in snapBenUSCounties.Name]\n",
    "snapBenUSCounties=snapBenUSCounties.assign(Name=counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick look:\n",
    "\n",
    "snapBenUSCounties.head() # last column will be ate the end..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a better column order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldNames=snapBenUSCounties.columns.tolist()\n",
    "oldNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNames=[*oldNames[:2],oldNames[-1],*oldNames[2:-1]]\n",
    "newNames          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reordering columns:\n",
    "\n",
    "snapBenUSCounties=snapBenUSCounties[newNames]\n",
    "snapBenUSCounties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST SAVING...\n",
    "#snapBenUSCounties.to_csv(\"snapBenUSCounties.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case: Multiple data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corruptLink='https://raw.githubusercontent.com/EvansDataScience/data/master/corruption.csv'\n",
    "econoLink='https://raw.githubusercontent.com/EvansDataScience/data/master/economic.csv'\n",
    "enviroLink='https://raw.githubusercontent.com/EvansDataScience/data/master/environment.csv'\n",
    "pressLink='https://raw.githubusercontent.com/EvansDataScience/data/master/pressfreedom.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The _corruptlink_ has data about the _Corruption Perception Index_ (CPI) produced by [Transparency International](https://www.transparency.org/).\n",
    "\n",
    "* The _econoLink_ has data about the _Economic Freedom Index_ (EFI) produced by [Fraser Institute](https://www.fraserinstitute.org).\n",
    "\n",
    "* The _enviroLink_ has data about the _Environment Performance Index_ (EPI) produced by [Yale University and Columbia University in collaboration with the World Economic Forum](https://epi.envirocenter.yale.edu/).\n",
    "\n",
    "* The _pressLink_ has data about the _World Press Freedom Index_ (WPFI) produced by [Reporters Without Borders](https://rsf.org/en/world-press-freedom-index).\n",
    "\n",
    "\n",
    "In this case, I want to join them (not concatenate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "corrupt=pd.read_csv(corruptLink,encoding='Latin-1')\n",
    "econo=pd.read_csv(econoLink,encoding='Latin-1')\n",
    "enviro=pd.read_csv(enviroLink,encoding='Latin-1')\n",
    "press=pd.read_csv(pressLink,encoding='Latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As each data set has a differing amount of rows (countries), and possibly a different way to name each one, the result will be far from perfect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join1=pd.merge(corrupt,econo)\n",
    "join2=pd.merge(press,enviro)\n",
    "indexes=pd.merge(join1,join2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always it is good to verify the data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check descriptives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes.describe(include='all') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some formatting needed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's order it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldCols=indexes.columns.tolist()\n",
    "oldCols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we do not have slices, there is extra work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericIndex=[oldCols[i] for i in [1,3,4,6]]\n",
    "numericIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newValues=[oldCols[0],oldCols[2],*numericIndex,oldCols[5],oldCols[7]]\n",
    "newValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the new order will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes=indexes[newValues]\n",
    "indexes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several numeric values. Let's see a summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to find some monotony issues in these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "pd.plotting.scatter_matrix(indexes.iloc[:,2:6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score press is negatively correlated to the rest. That means that the score for that column needs to be reversed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating reversing function:\n",
    "def reverse(aColumn):\n",
    "    return max(aColumn) - aColumn + min(aColumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reversing using function:\n",
    "indexes.scorepress=reverse(indexes.scorepress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see a different result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(indexes.iloc[:,2:6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable _presscat_ needs to be an ordinal factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes['presscat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes['presscat'].replace({'Medium':2, \"High\":3, \"Low\":1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes['presscat'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers will help R users when they set it as an ordinal. You can convert them to ordinal, but that information will be lost in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are proposing that the categories coded as numbers follow an asceding format, then let's check if _environmentCat_ should be changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes['environmentCat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there is no need for that, just save the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes.to_csv(\"indexes.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "____\n",
    "\n",
    "* [Go to page beginning](#beginning)\n",
    "* [Go to REPO in Github](https://github.com/EvansDataScience/ComputationalThinking_Gov_2)\n",
    "* [Go to Course schedule](https://evansdatascience.github.io/GovernanceAnalytics/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": true,
   "summary": "test"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
